{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GiuU7RrO-JkL"
      },
      "source": [
        "# Classical Model Training Using the CONNIE Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C9LHbRMGbDNj"
      },
      "outputs": [],
      "source": [
        "%run ./notebook_init.py\n",
        "\n",
        "import os\n",
        "import uproot\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "\n",
        "from core import MAIN_DIR\n",
        "from scripts.connie_training_utils import Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYJRXuPCqMdP"
      },
      "outputs": [],
      "source": [
        "processed_data_folder = os.path.join(MAIN_DIR, \"processed_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = Seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categories = [\"Alpha\", \"Blob\", \"Diffusion_Hit\", \"Electron\", \"Muon\", \"Others\"]\n",
        "branch_name = \"hitSumm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data_list = []\n",
        "all_data_list_excluded_vars = []\n",
        "\n",
        "print(\"Starting data loading\")\n",
        "for category in categories:\n",
        "    category_path = os.path.join(processed_data_folder, category)\n",
        "    root_files = glob(os.path.join(category_path, \"*.root\"))\n",
        "\n",
        "    if not root_files:\n",
        "        print(f\"Warning: No .root files found in {category_path}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing category: {category} ({len(root_files)} files)\")\n",
        "    for idx, file_path in enumerate(root_files):\n",
        "        try:\n",
        "            with uproot.open(file_path) as file:\n",
        "                if branch_name not in file:\n",
        "                    print(f\"Warning: TTree '{branch_name}' not found in {file_path}. Skipping.\")\n",
        "                    continue\n",
        "                file_branch = file[branch_name]\n",
        "                df = file_branch.arrays(library=\"pd\")\n",
        "                df['label'] = category\n",
        "                all_data_list.append(df)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {file_path}: {e}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combine all DataFrames into a single DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if all_data_list:\n",
        "    df_combined = pd.concat(all_data_list, ignore_index=True)\n",
        "    print(f\"Successfully loaded {len(df_combined)} rows of data.\")\n",
        "else:\n",
        "    print(\"No data loaded.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Calculate mean of ePix and level to be used as features\n",
        "* Remove features with more than one dimension, such as xPix and yPix\n",
        "* Remove \"flag\", as we already filtered for only valid events\n",
        "* Drop columns with no variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_processed = df_combined.copy()\n",
        "\n",
        "df_processed[\"ePixMean\"] = df_processed[\"ePix\"].apply(np.mean)\n",
        "df_processed[\"levelMean\"] = df_processed[\"level\"].apply(np.mean)\n",
        "\n",
        "df_processed = df_processed.drop(columns=[\"label\", \"xPix\", \"yPix\", \"level\", \"ePix\", \"flag\"])\n",
        "\n",
        "# Drop columns with no variance\n",
        "df_processed = df_processed.loc[:, df_processed.nunique() > 1]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculating the correlation between features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_df_combined = df_processed.corr()\n",
        "corr_pairs = corr_df_combined.unstack()\n",
        "# Filter out self-correlations\n",
        "filtered = corr_pairs[corr_pairs != 1.0]\n",
        "# Remove duplicate mirror entries\n",
        "filtered = filtered.drop_duplicates()\n",
        "# Find correlations above 0.9\n",
        "high_corr = filtered[filtered.abs() > 0.9]\n",
        "print(high_corr.sort_values(ascending=False))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Removing features from the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_processed_final = df_processed.drop(columns=[\"yBary0\", \"yBary1\", \"yVar1\",\"xBary0\", \"xBary1\",\n",
        "                                                \"ohdu\", \"E1\", \"n1\", \"NpixAC\", \"DeltaT\",\n",
        "                                                \"chid\", \"runID\", \"imgID\", \"skpID\", \"xMax\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Set all classes other than muons to label 0\n",
        "* Split the data into training and test sets\n",
        "* Use k-fold cross-validation for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_data = df_processed_final.copy()\n",
        "label_encoder = LabelEncoder()\n",
        "y_data = label_encoder.fit_transform(df_combined[\"label\"])\n",
        "\n",
        "class_name = \"Muon\"\n",
        "class_id = label_encoder.transform([class_name])[0]\n",
        "print(f\"Class ID for '{class_name}':{class_id}\\n\")\n",
        "\n",
        "for i, class_name in enumerate(label_encoder.classes_):\n",
        "    print(f\"Class ID {i}: {class_name}\")\n",
        "\n",
        "x_train_cv, x_test_final, y_train_cv, y_test_final = train_test_split(\n",
        "    x_data, y_data, test_size=0.15, random_state=seed.get_seed())\n",
        "\n",
        "# 1 if class 4, else 0\n",
        "y_binary_muon = (y_train_cv == class_id).astype(int)\n",
        "\n",
        "k_folds = 5\n",
        "kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=seed.get_seed())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xgb_train_scores = []\n",
        "xgb_val_scores = []\n",
        "rf_train_scores = []\n",
        "rf_val_scores = []\n",
        "\n",
        "for train_idx, val_idx in kf.split(x_train_cv, y_binary_muon):\n",
        "    x_train, X_val = x_train_cv.iloc[train_idx], x_train_cv.iloc[val_idx]\n",
        "    y_train, y_val = y_binary_muon[train_idx], y_binary_muon[val_idx]\n",
        "\n",
        "    # XGBoost model\n",
        "    xgb = XGBClassifier(n_estimators=300,\n",
        "                        use_label_encoder=False,\n",
        "                        eval_metric='logloss',\n",
        "                        gamma=0.98,\n",
        "                        learning_rate=0.05,\n",
        "                        random_state=seed.get_seed())\n",
        "    xgb.fit(x_train, y_train)\n",
        "    xgb_train_scores.append(accuracy_score(y_train, xgb.predict(x_train)))\n",
        "    xgb_val_scores.append(accuracy_score(y_val, xgb.predict(X_val)))\n",
        "\n",
        "    # Random Forest model\n",
        "    rf = RandomForestClassifier(n_estimators=300,\n",
        "                                max_features=0.3,\n",
        "                                min_samples_split=10,\n",
        "                                random_state=seed.get_seed())\n",
        "    rf.fit(x_train, y_train)\n",
        "    rf_train_scores.append(accuracy_score(y_train, rf.predict(x_train)))\n",
        "    rf_val_scores.append(accuracy_score(y_val, rf.predict(X_val)))\n",
        "\n",
        "\n",
        "print(f\"XGBoost - Train: {np.mean(xgb_train_scores):.4f}, Val: {np.mean(xgb_val_scores):.4f} ± {np.std(xgb_val_scores):.4f}\")\n",
        "print(f\"Random Forest - Train: {np.mean(rf_train_scores):.4f}, Val: {np.mean(rf_val_scores):.4f} ± {np.std(rf_val_scores):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TnQJJiRoGtYT"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
