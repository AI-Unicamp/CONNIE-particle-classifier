{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GiuU7RrO-JkL"
      },
      "source": [
        "# Model training with CONNIE image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9LHbRMGbDNj"
      },
      "outputs": [],
      "source": [
        "%run ./notebook_init.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "from collections import Counter\n",
        "from itertools import product\n",
        "from pathlib import Path\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "from core import DATA_FOLDER\n",
        "\n",
        "from scripts.connie_training_utils import ModelTraining, TransformedSubset, \\\n",
        "    Seed, get_test_transform, IMG_SIZE,\\\n",
        "    get_train_transform, calculate_mean_std"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load file paths and set the computation device to GPU if available; otherwise, use CPU, and initialize the random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYJRXuPCqMdP"
      },
      "outputs": [],
      "source": [
        "processed_data_folder = os.path.join(DATA_FOLDER, \"png_processed_data\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "seed = Seed()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute dataset mean and standard deviation, then define training and test transforms with normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "basic_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load dataset without transform\n",
        "full_dataset_transform = datasets.ImageFolder(processed_data_folder, transform=basic_transform)\n",
        "\n",
        "mean, std = calculate_mean_std(full_dataset_transform)\n",
        "test_transform = get_test_transform(mean, std)\n",
        "train_transform = get_train_transform(mean, std)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split train + validation and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_dataset = datasets.ImageFolder(processed_data_folder)\n",
        "total_len = len(full_dataset)\n",
        "trainval_len = int(0.85 * total_len)\n",
        "test_len = total_len - trainval_len\n",
        "\n",
        "trainval_set, test_set = random_split(full_dataset, [trainval_len, test_len],\n",
        "                                      generator=seed.generator())\n",
        "\n",
        "# Apply eval_transform to test set\n",
        "test_set = TransformedSubset(test_set, test_transform)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set all classes other than muons to label 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_idx_map = full_dataset.class_to_idx\n",
        "print(\"Classes index:  \", class_idx_map)\n",
        "muon_idx = class_idx_map['Muon']\n",
        "full_dataset.targets = [1 if target == muon_idx else 0 for target in full_dataset.targets]\n",
        "print(\"Label distribution:\", Counter(full_dataset.targets))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training with K-fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define your parameter grid\n",
        "param_grid = {\n",
        "    \"learning_rate\": [5e-4],\n",
        "    'weight_decay': [5e-5],\n",
        "    \"step_size\": [10],\n",
        "    \"gamma\": [0.5]\n",
        "}\n",
        "\n",
        "# Create all combinations\n",
        "grid = list(product(\n",
        "    param_grid[\"learning_rate\"],\n",
        "    param_grid[\"weight_decay\"],\n",
        "    param_grid[\"step_size\"],\n",
        "    param_grid[\"gamma\"]\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "k_folds = 5\n",
        "num_epochs = 100\n",
        "\n",
        "best_acc = 0.0\n",
        "best_model = None\n",
        "best_params = None\n",
        "all_results = []\n",
        "\n",
        "model_training = ModelTraining()\n",
        "\n",
        "for i, (lr, wd, step_size, gamma) in enumerate(grid):\n",
        "    print(f\"\\nGrid Search {i+1}/{len(grid)} â€” LR={lr}, WD={wd}, Step={step_size}, Gamma={gamma}\")\n",
        "    hyperparam = {\"lr\": lr, \"wd\": wd, \"step\": step_size, \"gamma\": gamma}\n",
        "\n",
        "    model, val_acc = model_training.train_model_kfold(device, trainval_set,\n",
        "                                                      num_epochs, train_transform,\n",
        "                                                      test_transform, k_folds, muon_idx,\n",
        "                                                      seed, hyperparam)\n",
        "    all_results.append(((lr, wd, step_size, gamma), val_acc))\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_model = model\n",
        "        best_params = (lr, wd, step_size, gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Best Hyperparameters:\")\n",
        "print(f\"Learning Rate: {best_params[0]}\")\n",
        "print(f\"Weight Decay:  {best_params[1]}\")\n",
        "print(f\"Step Size:     {best_params[2]}\")\n",
        "print(f\"Gamma:         {best_params[3]}\")\n",
        "print(f\"CV Accuracy:   {best_acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TnQJJiRoGtYT"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
